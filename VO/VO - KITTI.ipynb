{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhATaaotWpYY"
   },
   "source": [
    "# Visual Odometry for KITTI Dataset\n",
    "\n",
    "Implementation of VO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nvWOLW-YUMv"
   },
   "source": [
    "## Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1612557785555,
     "user": {
      "displayName": "Taeyoung Lee",
      "photoUrl": "",
      "userId": "07906618747313337531"
     },
     "user_tz": 300
    },
    "id": "f7eDiZtVX6DM",
    "outputId": "79b61644-4fd1-4046-c98d-fbc6a8a3d93a"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# %cd '/content/drive/MyDrive/Colab Notebooks'\n",
    "\n",
    "# import numpy as np\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import math\n",
    "# import scipy.signal\n",
    "# import scipy.linalg\n",
    "# import importlib\n",
    "# import mae6292.tools as mae6292\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "# from google.colab import files as FILE\n",
    "# import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaFe_Ot-ziRV"
   },
   "source": [
    "## Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "error",
     "timestamp": 1612557788001,
     "user": {
      "displayName": "Taeyoung Lee",
      "photoUrl": "",
      "userId": "07906618747313337531"
     },
     "user_tz": 300
    },
    "id": "XOGSROrK6oGt",
    "outputId": "201bf5ab-4d81-436e-cb82-4c62e1feaf32"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import scipy.signal\n",
    "import scipy.linalg\n",
    "import mae6292.tools as mae6292\n",
    "import importlib\n",
    "\n",
    "from mae6292.imshow import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEUEyf2dPM-4"
   },
   "source": [
    "## Boostrapping\n",
    "\n",
    "Bootstrapping to initilize VO has been implemented by\n",
    "```\n",
    "keypoints0, p_W0, R1, T1 = mae6292.VO_bootstrap(img0, img1, K, display = False)   \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N_keypoints0= 851\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(mae6292)\n",
    "\n",
    "K = np.loadtxt('data/K.txt')\n",
    "img0 = cv2.imread('data/000000.png', cv2.IMREAD_GRAYSCALE)\n",
    "img1 = cv2.imread('data/000001.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# PARAMETERS\n",
    "param_bootstrap = {\n",
    "    # keypoints\n",
    "    'W_harris_patch' : 4, # size of harris patch\n",
    "    'kappa_harris' : 0.08, # kappa for harris score\n",
    "    'N_keypoint' : 2000, # number of keypoints to be detected\n",
    "    'W_nms' : 8, # patch size for non-maximum supression\n",
    "    # KLT\n",
    "    'W_KLT' : 4, # patch size for KLT\n",
    "    'tol_KLT_bidir' : 1, # tolerence of bidirectional error\n",
    "    # find essential matrix\n",
    "    'tol_E' : 1, # tolerence for epipolar line distance\n",
    "    'tol_E_RANSAC_prob' : 0.99, # eseential matrix RANSAC probability\n",
    "    # triangulation\n",
    "    'tol_TRI_mu' : 1e-3, # tolerence for the singular value ratio\n",
    "    'tol_TRI_rep' : 1 # tolerence for the reprojection error\n",
    "}\n",
    "\n",
    "keypoints0, p_W0, R1, T1 = mae6292.VO_bootstrap(img0, img1, K, param_bootstrap, display = True)   \n",
    "scale = 0.693071855459021\n",
    "T1 = T1*scale\n",
    "p_W0 = p_W0*scale\n",
    "\n",
    "print('N_keypoints0=',len(keypoints0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization and Mapping\n",
    "\n",
    "\n",
    "The sequential process for localization and mapping has been implemented by\n",
    "```\n",
    "    R, T, S, C, fig = mae6292.VO_localization_mapping(i_frame, K, img, img_pre, S_pre, C_pre, display_process=True)\n",
    "```\n",
    "Each frame is saved under the folder `output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i_frame= 1\n",
      "R= [[ 0.99999267  0.00327993  0.00197406]\n",
      " [-0.00328373  0.99999276  0.00192176]\n",
      " [-0.00196774 -0.00192822  0.9999962 ]]\n",
      "T_W= [-0.01356089 -0.00294668  0.69992327]\n",
      " \n",
      "i_frame= 2\n",
      "S_pre= 851 , KLT_matched= 671 , PnP_inliers= 669 , S_new =  901\n",
      "C_pre= 593 , KLT_matched= 415 , TRI_inliers= 232 , C_new =  333\n",
      "R= [[ 0.99998542  0.00211629  0.0049686 ]\n",
      " [-0.00213458  0.99999096  0.00367715]\n",
      " [-0.00496077 -0.00368771  0.9999809 ]]\n",
      "T_W= [-3.65094029e-02  2.02511934e-04  1.43034279e+00]\n",
      " \n",
      "i_frame= 3\n",
      "S_pre= 901 , KLT_matched= 793 , PnP_inliers= 787 , S_new =  823\n",
      "C_pre= 333 , KLT_matched= 169 , TRI_inliers= 36 , C_new =  374\n",
      "R= [[ 0.99996371  0.00219175  0.00823262]\n",
      " [-0.00223501  0.99998372  0.00524964]\n",
      " [-0.00822098 -0.00526785  0.99995233]]\n",
      "T_W= [-5.82628984e-02  2.14676680e-03  2.18313254e+00]\n",
      " \n",
      "i_frame= 4\n",
      "S_pre= 823 , KLT_matched= 721 , PnP_inliers= 692 , S_new =  711\n",
      "C_pre= 374 , KLT_matched= 167 , TRI_inliers= 19 , C_new =  372\n",
      "R= [[ 9.99930615e-01  6.94619468e-04  1.17593529e-02]\n",
      " [-7.66440525e-04  9.99981076e-01  6.10416432e-03]\n",
      " [-1.17548903e-02 -6.11275363e-03  9.99912225e-01]]\n",
      "T_W= [-1.03528669e-01  1.08664484e-03  2.96834598e+00]\n",
      " \n",
      "i_frame= 5\n",
      "S_pre= 711 , KLT_matched= 627 , PnP_inliers= 617 , S_new =  631\n",
      "C_pre= 372 , KLT_matched= 180 , TRI_inliers= 14 , C_new =  357\n",
      "R= [[ 0.99988003  0.00163546  0.01540274]\n",
      " [-0.00174042  0.99997534  0.00680342]\n",
      " [-0.01539123 -0.00682941  0.99985822]]\n",
      "T_W= [-0.13281316  0.00387078  3.77483162]\n",
      " \n",
      "i_frame= 6\n",
      "S_pre= 631 , KLT_matched= 563 , PnP_inliers= 490 , S_new =  510\n",
      "C_pre= 357 , KLT_matched= 172 , TRI_inliers= 20 , C_new =  455\n",
      "R= [[ 9.99811797e-01 -6.63975123e-05  1.94001754e-02]\n",
      " [-8.98074655e-05  9.99967588e-01  8.05074803e-03]\n",
      " [-1.94000811e-02 -8.05097513e-03  9.99779385e-01]]\n",
      "T_W= [-0.18750278 -0.00823549  4.57717294]\n",
      " \n",
      "i_frame= 7\n",
      "S_pre= 510 , KLT_matched= 459 , PnP_inliers= 447 , S_new =  496\n",
      "C_pre= 455 , KLT_matched= 233 , TRI_inliers= 49 , C_new =  401\n",
      "R= [[ 0.99971398 -0.00309502  0.02371437]\n",
      " [ 0.00288034  0.99995461  0.0090814 ]\n",
      " [-0.0237414  -0.00901049  0.99967753]]\n",
      "T_W= [-0.2248171  -0.01019058  5.41609493]\n",
      " \n",
      "i_frame= 8\n",
      "S_pre= 496 , KLT_matched= 426 , PnP_inliers= 365 , S_new =  398\n",
      "C_pre= 401 , KLT_matched= 213 , TRI_inliers= 33 , C_new =  581\n",
      "R= [[ 0.99964228 -0.00329139  0.02654215]\n",
      " [ 0.00308926  0.99996595  0.00765279]\n",
      " [-0.02656643 -0.00756805  0.9996184 ]]\n",
      "T_W= [-0.30854004 -0.02070345  6.32438272]\n",
      " \n",
      "i_frame= 9\n",
      "S_pre= 398 , KLT_matched= 345 , PnP_inliers= 310 , S_new =  408\n",
      "C_pre= 581 , KLT_matched= 277 , TRI_inliers= 98 , C_new =  533\n",
      "R= [[ 0.99948946 -0.00244278  0.03185661]\n",
      " [ 0.00226971  0.99998248  0.00546784]\n",
      " [-0.03186941 -0.00539274  0.99947749]]\n",
      "T_W= [-0.3385121  -0.02426711  7.20381954]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#open a new window for plot\n",
    "%matplotlib tk \n",
    "importlib.reload(mae6292)\n",
    "\n",
    "# PARAMETERS\n",
    "param = {\n",
    "    # keypoints\n",
    "    'W_harris_patch' : 4, # size of harris patch\n",
    "    'kappa_harris' : 0.08, # kappa for harris score\n",
    "    'N_keypoint' : 2000, # number of keypoints to be detected\n",
    "    'W_nms' : 8, # patch size for non-maximum supression\n",
    "    # KLT\n",
    "    'W_KLT' : 4, # patch size for KLT\n",
    "    'tol_KLT_bidir' : 1, # tolerence of bidirectional error\n",
    "    # triangulation\n",
    "    'tol_TRI_mu' : 1e-3, # tolerence for the singular value ratio\n",
    "    'tol_TRI_rep' : 0.5, # tolerence for the reprojection error\n",
    "    # mapping\n",
    "    'tol_keypoints_new' : 20 # new keypoints should be district from the tracked keypoints by this distance\n",
    "}\n",
    "\n",
    "# iniitlize iteration\n",
    "img_pre = img0\n",
    "S_pre = mae6292.state(keypoints0, p_W0, [np.zeros((3,1))])\n",
    "C_pre = mae6292.candidate([],[],[],[])\n",
    "\n",
    "# varialbes to save the vehicle location and the keypoints in the W-frame \n",
    "T_W = np.zeros((3,N_frames))\n",
    "p_W = p_W0\n",
    "\n",
    "# number of frames to process\n",
    "N_frames = 10\n",
    "# boolean \n",
    "display_process = False\n",
    "\n",
    "for i_frame in range(1,N_frames):\n",
    "    \n",
    "    print('i_frame=',i_frame)\n",
    "\n",
    "    # VO localization and mapping\n",
    "    img = cv2.imread(\"data/{:06d}.png\".format(i_frame),cv2.IMREAD_GRAYSCALE)\n",
    "    R, T, S, C, fig = mae6292.VO_localization_mapping(i_frame, img, img_pre, S_pre, C_pre, K, param)\n",
    "    img_pre, S_pre, C_pre = img, S, C\n",
    "\n",
    "    # save figure \n",
    "    if display_process:\n",
    "        fig.savefig(\"output/{:06d}.png\".format(i_frame))\n",
    "\n",
    "    # save the vehicle location and the distinct keypoints \n",
    "    T_W[:,i_frame] = (-R.T@T).flatten()\n",
    "    p_W_dist = scipy.spatial.distance.cdist( S.p_W.T, p_W.T , 'euclidean')\n",
    "    index_distinct = np.where( np.min(p_W_dist, axis=1) > 3 )[0]\n",
    "    p_W = np.append(p_W, S.p_W[:,index_distinct], axis=1)\n",
    "\n",
    "    # print pose\n",
    "    print('R=',R)\n",
    "    print('T_W=',(-R.T@T).flatten())\n",
    "    print(' ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "The following codes visualize the vehicle trajectory and the keypoints in the W-frame. \n",
    "\n",
    "(You may need to adjust th eaxis limit)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection = '3d')\n",
    "ax.plot(T_W[0,:], T_W[1,:], T_W[2,:], 'b')\n",
    "ax.scatter(p_W[0,:], p_W[1,:], p_W[2,:], s=1, c='r', marker='o')\n",
    "ax.set_xlim(-10,20)\n",
    "ax.set_zlim(-2,20)\n",
    "ax.set_xlabel('x',fontsize=6)\n",
    "ax.set_ylabel('y',fontsize=6)\n",
    "ax.set_zlabel('z',fontsize=6)\n",
    "ax.view_init(elev=0., azim=-90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video\n",
    "\n",
    "The output images can be converted into a video as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = []\n",
    "\n",
    "for i_frame in range(1,N_frames):\n",
    "    filename = \"output/{:06d}.png\".format(i_frame)\n",
    "    img = cv2.imread(filename)\n",
    "    img_array.append(img)\n",
    "\n",
    "height, width, layers = img.shape\n",
    "size = (width,height)\n",
    "\n",
    "fps = 3\n",
    "codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4',codec, fps, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "YaFe_Ot-ziRV"
   ],
   "name": "image_filtering.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python383jvsc74a57bd0bef35c445fba6c94349e1da747e7a89e5d483044f8a626d9f3383914aebf9cae",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}